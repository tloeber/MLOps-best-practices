{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading raw data from schema-less format (e.g., csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version: 2.1.2\n",
      "pyarrow version: 14.0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "print(f\"pandas version: {pd.__version__}\")\n",
    "print(f\"pyarrow version: {pa.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example data\n",
    "As the example data, I will be using the famous NYC taxi data set. I picked it because:\n",
    "- it contains a good mix of column datatypes that we would want to parse for typical use cases (in particular, including datetime).\n",
    "- it is large enough (~1.5 million rows) to allow us to do meaningful performance comparisons.\n",
    "\n",
    "It does not contain any missing values; therefore, I artificially introduced missing values in different ways, so we can look at how this affects Arrow's ability to correctly infer the schema or parse the data into a given schema. Likewise, it will show us whether we get meaningful error messages. I have moved the set up code into a different notebook at data/data_setup.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_MISSING_AS_EMPTY_STRING = 'data/missing_as_empty_string.csv'\n",
    "PATH_MISSING_AS_STRING = 'data/missing_as_string.csv'\n",
    "PATH_MISSING_AS_MULTIPLE_STRINGS = 'data/missing_as_multiple_strings.csv'\n",
    "MISSING_AS_QUESTION_MARKS = 'data/missing_as_question_marks.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Reading using schema *inference*\n",
    "Note that automatic type inference works for some representations of missing values. Both empty string and \"NA\" is properly recognized, whereas \"???\" is not and leads to all columns being interpreted as strings.\n",
    "\n",
    "### Missing values encoded as EMPTY STRING\n",
    "Let's take a look at what the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,vendor_id,pickup_datetime,dropoff_datetime,passenger_count,pickup_longitude,pickup_latitude,dropoff_longitude,dropoff_latitude,store_and_fwd_flag,trip_duration\n",
      "id2875421,2.0,2016-03-14 17:24:55,2016-03-14 17:32:30,1.0,-73.98215484619139,40.76793670654297,-73.96463012695312,40.765602111816406,N,455.0\n",
      ",,,,,,,,,,\n",
      "id3858529,2.0,2016-01-19 11:35:24,2016-01-19 12:10:48,1.0,-73.97902679443358,40.763938903808594,-74.00533294677734,40.710086822509766,N,2124.0\n"
     ]
    }
   ],
   "source": [
    "!head -n 4 data/missing_as_empty_string.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 900 ms, sys: 369 ms, total: 1.27 s\n",
      "Wall time: 155 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                          string[pyarrow]\n",
       "vendor_id                   double[pyarrow]\n",
       "pickup_datetime       timestamp[s][pyarrow]\n",
       "dropoff_datetime      timestamp[s][pyarrow]\n",
       "passenger_count             double[pyarrow]\n",
       "pickup_longitude            double[pyarrow]\n",
       "pickup_latitude             double[pyarrow]\n",
       "dropoff_longitude           double[pyarrow]\n",
       "dropoff_latitude            double[pyarrow]\n",
       "store_and_fwd_flag          string[pyarrow]\n",
       "trip_duration               double[pyarrow]\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pd.read_csv(\n",
    "    PATH_MISSING_AS_EMPTY_STRING,\n",
    "    engine='pyarrow',\n",
    "    dtype_backend='pyarrow',\n",
    ") \\\n",
    ".dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing encoded as 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,vendor_id,pickup_datetime,dropoff_datetime,passenger_count,pickup_longitude,pickup_latitude,dropoff_longitude,dropoff_latitude,store_and_fwd_flag,trip_duration\n",
      "id2875421,2.0,2016-03-14 17:24:55,2016-03-14 17:32:30,1.0,-73.98215484619139,40.76793670654297,-73.96463012695312,40.765602111816406,N,455.0\n",
      "NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA\n",
      "id3858529,2.0,2016-01-19 11:35:24,2016-01-19 12:10:48,1.0,-73.97902679443358,40.763938903808594,-74.00533294677734,40.710086822509766,N,2124.0\n"
     ]
    }
   ],
   "source": [
    "!head -n 4 data/missing_as_string.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 966 ms, sys: 325 ms, total: 1.29 s\n",
      "Wall time: 199 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                          string[pyarrow]\n",
       "vendor_id                   double[pyarrow]\n",
       "pickup_datetime       timestamp[s][pyarrow]\n",
       "dropoff_datetime      timestamp[s][pyarrow]\n",
       "passenger_count             double[pyarrow]\n",
       "pickup_longitude            double[pyarrow]\n",
       "pickup_latitude             double[pyarrow]\n",
       "dropoff_longitude           double[pyarrow]\n",
       "dropoff_latitude            double[pyarrow]\n",
       "store_and_fwd_flag          string[pyarrow]\n",
       "trip_duration               double[pyarrow]\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\n",
    "    PATH_MISSING_AS_STRING,\n",
    "    engine='pyarrow',\n",
    "    dtype_backend='pyarrow',\n",
    ")\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>trip_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id2875421</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-03-14 17:24:55</td>\n",
       "      <td>2016-03-14 17:32:30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-73.982155</td>\n",
       "      <td>40.767937</td>\n",
       "      <td>-73.96463</td>\n",
       "      <td>40.765602</td>\n",
       "      <td>N</td>\n",
       "      <td>455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id3858529</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-01-19 11:35:24</td>\n",
       "      <td>2016-01-19 12:10:48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-73.979027</td>\n",
       "      <td>40.763939</td>\n",
       "      <td>-74.005333</td>\n",
       "      <td>40.710087</td>\n",
       "      <td>N</td>\n",
       "      <td>2124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id3504673</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-04-06 19:32:31</td>\n",
       "      <td>2016-04-06 19:39:40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-74.01004</td>\n",
       "      <td>40.719971</td>\n",
       "      <td>-74.012268</td>\n",
       "      <td>40.706718</td>\n",
       "      <td>N</td>\n",
       "      <td>429.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id2181028</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-03-26 13:30:55</td>\n",
       "      <td>2016-03-26 13:38:10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-73.973053</td>\n",
       "      <td>40.793209</td>\n",
       "      <td>-73.972923</td>\n",
       "      <td>40.78252</td>\n",
       "      <td>N</td>\n",
       "      <td>435.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  vendor_id      pickup_datetime     dropoff_datetime  \\\n",
       "0  id2875421        2.0  2016-03-14 17:24:55  2016-03-14 17:32:30   \n",
       "1       <NA>       <NA>                 <NA>                 <NA>   \n",
       "2  id3858529        2.0  2016-01-19 11:35:24  2016-01-19 12:10:48   \n",
       "3  id3504673        2.0  2016-04-06 19:32:31  2016-04-06 19:39:40   \n",
       "4  id2181028        2.0  2016-03-26 13:30:55  2016-03-26 13:38:10   \n",
       "\n",
       "   passenger_count  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "0              1.0        -73.982155        40.767937          -73.96463   \n",
       "1             <NA>              <NA>             <NA>               <NA>   \n",
       "2              1.0        -73.979027        40.763939         -74.005333   \n",
       "3              1.0         -74.01004        40.719971         -74.012268   \n",
       "4              1.0        -73.973053        40.793209         -73.972923   \n",
       "\n",
       "   dropoff_latitude store_and_fwd_flag  trip_duration  \n",
       "0         40.765602                  N          455.0  \n",
       "1              <NA>               <NA>           <NA>  \n",
       "2         40.710087                  N         2124.0  \n",
       "3         40.706718                  N          429.0  \n",
       "4          40.78252                  N          435.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing encoded as 'NA' or 'nan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 860 ms, sys: 1.13 s, total: 1.99 s\n",
      "Wall time: 130 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                          string[pyarrow]\n",
       "vendor_id                   double[pyarrow]\n",
       "pickup_datetime       timestamp[s][pyarrow]\n",
       "dropoff_datetime      timestamp[s][pyarrow]\n",
       "passenger_count             double[pyarrow]\n",
       "pickup_longitude            double[pyarrow]\n",
       "pickup_latitude             double[pyarrow]\n",
       "dropoff_longitude           double[pyarrow]\n",
       "dropoff_latitude            double[pyarrow]\n",
       "store_and_fwd_flag          string[pyarrow]\n",
       "trip_duration               double[pyarrow]\n",
       "dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\n",
    "    PATH_MISSING_AS_MULTIPLE_STRINGS,\n",
    "    engine='pyarrow',\n",
    "    dtype_backend='pyarrow',\n",
    ")\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values encoded as \"???\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.03 s, sys: 1.34 s, total: 2.37 s\n",
      "Wall time: 312 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                    string[pyarrow]\n",
       "vendor_id             string[pyarrow]\n",
       "pickup_datetime       string[pyarrow]\n",
       "dropoff_datetime      string[pyarrow]\n",
       "passenger_count       string[pyarrow]\n",
       "pickup_longitude      string[pyarrow]\n",
       "pickup_latitude       string[pyarrow]\n",
       "dropoff_longitude     string[pyarrow]\n",
       "dropoff_latitude      string[pyarrow]\n",
       "store_and_fwd_flag    string[pyarrow]\n",
       "trip_duration         string[pyarrow]\n",
       "dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pd.read_csv(\n",
    "    MISSING_AS_QUESTION_MARKS,\n",
    "    engine='pyarrow',\n",
    "    dtype_backend='pyarrow',\n",
    ") \\\n",
    ".dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) *Partial* schema inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it is possible to specify schema for only a *subset* of columns. (This is okay for interactive usage, but should not be done in production):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.26 s, sys: 453 ms, total: 1.71 s\n",
      "Wall time: 533 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                    string[python]\n",
       "vendor_id                    float64\n",
       "pickup_datetime        datetime64[s]\n",
       "dropoff_datetime       datetime64[s]\n",
       "passenger_count              float64\n",
       "pickup_longitude             float64\n",
       "pickup_latitude              float64\n",
       "dropoff_longitude            float64\n",
       "dropoff_latitude             float64\n",
       "store_and_fwd_flag            object\n",
       "trip_duration                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "schema_pd = {'id': 'string'}\n",
    "\n",
    "df = pd.read_csv(\n",
    "    'data/missing_as_empty_string.csv',\n",
    "    engine='pyarrow',\n",
    "    dtype=schema_pd,\n",
    ")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, it works to specify that vendor ID is an integer, even though it is encoded like a float (e.g., \"2.0\" rather than \"2\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.43 s, sys: 263 ms, total: 1.69 s\n",
      "Wall time: 506 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                            object\n",
       "vendor_id             int16[pyarrow]\n",
       "pickup_datetime        datetime64[s]\n",
       "dropoff_datetime       datetime64[s]\n",
       "passenger_count              float64\n",
       "pickup_longitude             float64\n",
       "pickup_latitude              float64\n",
       "dropoff_longitude            float64\n",
       "dropoff_latitude             float64\n",
       "store_and_fwd_flag            object\n",
       "trip_duration                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "schema_pd = {\n",
    "    'vendor_id': 'int16[pyarrow]',\n",
    "}\n",
    "df = pd.read_csv(\n",
    "    'data/missing_as_empty_string.csv',\n",
    "    engine='pyarrow',\n",
    "    dtype=schema_pd,\n",
    ")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['N', None, 'Y'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.store_and_fwd_flag.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Reading using *explicit* schema\n",
    "Again, this works for reasonably-standard encodings of missing values (in our case, \"\", \"NA\", and a combination of \"NA\" and \"nan\":\n",
    "### Works: Missing values as empty strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.56 s, sys: 278 ms, total: 1.83 s\n",
      "Wall time: 592 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                          string[pyarrow]\n",
       "vendor_id                    int16[pyarrow]\n",
       "pickup_datetime       timestamp[s][pyarrow]\n",
       "dropoff_datetime      timestamp[s][pyarrow]\n",
       "passenger_count               int8[pyarrow]\n",
       "pickup_longitude             float[pyarrow]\n",
       "pickup_latitude              float[pyarrow]\n",
       "dropoff_longitude            float[pyarrow]\n",
       "dropoff_latitude             float[pyarrow]\n",
       "store_and_fwd_flag          string[pyarrow]\n",
       "trip_duration                float[pyarrow]\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "schema_pd = {\n",
    "    'id': 'string[pyarrow]',\n",
    "    'vendor_id': 'int16[pyarrow]',\n",
    "    'pickup_datetime': 'timestamp[s][pyarrow]',\n",
    "    'dropoff_datetime': 'timestamp[s][pyarrow]',\n",
    "    'passenger_count': 'int8[pyarrow]',\n",
    "    'pickup_longitude': 'float32[pyarrow]',\n",
    "    'pickup_latitude': 'float32[pyarrow]',\n",
    "    'dropoff_longitude': 'float32[pyarrow]',\n",
    "    'dropoff_latitude': 'float32[pyarrow]',\n",
    "    'store_and_fwd_flag': 'string[pyarrow]',\n",
    "    'trip_duration': 'float32[pyarrow]',\n",
    "}\n",
    "df = pd.read_csv(\n",
    "    'data/missing_as_empty_string.csv',\n",
    "    engine='pyarrow',\n",
    "    dtype=schema_pd,\n",
    ")\n",
    "dtypes_schema = df.dtypes\n",
    "dtypes_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Works: Missing encoded as 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.01 s, sys: 1.06 s, total: 2.07 s\n",
      "Wall time: 385 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                          string[pyarrow]\n",
       "vendor_id                    int16[pyarrow]\n",
       "pickup_datetime       timestamp[s][pyarrow]\n",
       "dropoff_datetime      timestamp[s][pyarrow]\n",
       "passenger_count               int8[pyarrow]\n",
       "pickup_longitude             float[pyarrow]\n",
       "pickup_latitude              float[pyarrow]\n",
       "dropoff_longitude            float[pyarrow]\n",
       "dropoff_latitude             float[pyarrow]\n",
       "store_and_fwd_flag          string[pyarrow]\n",
       "trip_duration                float[pyarrow]\n",
       "dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\n",
    "    PATH_MISSING_AS_STRING,\n",
    "    engine='pyarrow',\n",
    "    dtype_backend='pyarrow',\n",
    "    dtype=schema_pd,\n",
    ")\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Works: Missing encoded as 'NA' or 'nan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.14 s, sys: 609 ms, total: 1.75 s\n",
      "Wall time: 502 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                          string[pyarrow]\n",
       "vendor_id                    int16[pyarrow]\n",
       "pickup_datetime       timestamp[s][pyarrow]\n",
       "dropoff_datetime      timestamp[s][pyarrow]\n",
       "passenger_count               int8[pyarrow]\n",
       "pickup_longitude             float[pyarrow]\n",
       "pickup_latitude              float[pyarrow]\n",
       "dropoff_longitude            float[pyarrow]\n",
       "dropoff_latitude             float[pyarrow]\n",
       "store_and_fwd_flag          string[pyarrow]\n",
       "trip_duration                float[pyarrow]\n",
       "dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\n",
    "    PATH_MISSING_AS_MULTIPLE_STRINGS,\n",
    "    engine='pyarrow',\n",
    "    dtype_backend='pyarrow',\n",
    "    dtype=schema_pd,\n",
    ")\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fails: Missing values encoded as \"???\"\n",
    "However, reading the file fails with less-standard encodings of missing values, such as \"???\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to parse string: '1.0' as a scalar of type int16: Error while type casting for column 'vendor_id'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    pd.read_csv(\n",
    "        MISSING_AS_QUESTION_MARKS,\n",
    "        engine='pyarrow',\n",
    "        dtype_backend='pyarrow',\n",
    "        dtype=schema_pd,\n",
    "    )\n",
    "except pa.ArrowInvalid as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Interestingly, **the error message is not always very useful in telling us why exactly the data could not be parsed into the supplied schema:**\n",
    "In the below case, it complains that the string \"1.0\" could not be parsed to integer. This makes it sound like it is some sort of limitation on the side of Arrow not being able to perform the simple casting. However, we know from the above examples that this is not in fact the problem, because the different encoding of missing values vendor_id was successfully parsed to an individual column without any issues. The actual problem is the string \"???\" which it cannot cast into an integer (or recognize as a missing value indicator). Presumably the error message just gives us the value in the first row of the column failing, rather than the actual element in that column that is causing the issue. \n",
    "\n",
    "Let's remove vendor_id from the schema and see what error the next column raises:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to parse string: '???' as a scalar of type timestamp[s]: Error while type casting for column 'pickup_datetime'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    pd.read_csv(\n",
    "        MISSING_AS_QUESTION_MARKS,\n",
    "        engine='pyarrow',\n",
    "        dtype_backend='pyarrow',\n",
    "        dtype={\n",
    "            'id': 'string[pyarrow]',\n",
    "            # 'vendor_id': 'int16[pyarrow]',\n",
    "            'pickup_datetime': 'timestamp[s][pyarrow]',\n",
    "            'dropoff_datetime': 'timestamp[s][pyarrow]',\n",
    "            'passenger_count': 'int8[pyarrow]',\n",
    "            'pickup_longitude': 'float32[pyarrow]',\n",
    "            'pickup_latitude': 'float32[pyarrow]',\n",
    "            'dropoff_longitude': 'float32[pyarrow]',\n",
    "            'dropoff_latitude': 'float32[pyarrow]',\n",
    "            'store_and_fwd_flag': 'string[pyarrow]',\n",
    "            'trip_duration': 'float32[pyarrow]',\n",
    "        },\n",
    "    )\n",
    "except pa.ArrowInvalid as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, in the case of the failed parsing of the timestamp, it does signal out \"???\" as the cause of the problem.\n",
    "\n",
    "Let's try removing the timestamp columns from the schema as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to parse string: '1.0' as a scalar of type int8: Error while type casting for column 'passenger_count'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    pd.read_csv(\n",
    "        MISSING_AS_QUESTION_MARKS,\n",
    "        engine='pyarrow',\n",
    "        dtype_backend='pyarrow',\n",
    "        dtype={\n",
    "            'id': 'string[pyarrow]',\n",
    "            # 'vendor_id': 'int16[pyarrow]',\n",
    "            # 'pickup_datetime': 'timestamp[s][pyarrow]',\n",
    "            # 'dropoff_datetime': 'timestamp[s][pyarrow]',\n",
    "            'passenger_count': 'int8[pyarrow]',\n",
    "            'pickup_longitude': 'float32[pyarrow]',\n",
    "            'pickup_latitude': 'float32[pyarrow]',\n",
    "            'dropoff_longitude': 'float32[pyarrow]',\n",
    "            'dropoff_latitude': 'float32[pyarrow]',\n",
    "            'store_and_fwd_flag': 'string[pyarrow]',\n",
    "            'trip_duration': 'float32[pyarrow]',\n",
    "        },\n",
    "    )\n",
    "except pa.ArrowInvalid as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column causing problems in the schema is an integer column, and we get the same result as for the previous integer column, vendor_id: It misleadingly complains that the string of \"1.0\" cannot be parsed to integer.\n",
    "\n",
    "Let's try one more thing, namely what happens in the case of floats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to parse string: '???' as a scalar of type float: Error while type casting for column 'pickup_longitude'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    pd.read_csv(\n",
    "        MISSING_AS_QUESTION_MARKS,\n",
    "        engine='pyarrow',\n",
    "        dtype_backend='pyarrow',\n",
    "        dtype={\n",
    "            'id': 'string[pyarrow]',\n",
    "            # 'vendor_id': 'int16[pyarrow]',\n",
    "            # 'pickup_datetime': 'timestamp[s][pyarrow]',\n",
    "            # 'dropoff_datetime': 'timestamp[s][pyarrow]',\n",
    "            # 'passenger_count': 'int8[pyarrow]',\n",
    "            'pickup_longitude': 'float32[pyarrow]',\n",
    "            'pickup_latitude': 'float32[pyarrow]',\n",
    "            'dropoff_longitude': 'float32[pyarrow]',\n",
    "            'dropoff_latitude': 'float32[pyarrow]',\n",
    "            'store_and_fwd_flag': 'string[pyarrow]',\n",
    "            'trip_duration': 'float32[pyarrow]',\n",
    "        },\n",
    "    )\n",
    "except pa.ArrowInvalid as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, it does give us the right error message for floats, like in the case of timestamps. So **the problem seems to be confined to integers.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-pipelines-6zazC8F6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
